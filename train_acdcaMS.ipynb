{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_acdcaMS.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"matqiSE04ofO","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"error","timestamp":1618557778003,"user_tz":-420,"elapsed":8956,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"}},"outputId":"c8f22542-32f8-4840-c288-0791e4066010"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nrJZWuXAKfAs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486373344,"user_tz":-420,"elapsed":6069,"user":{"displayName":"hi trum","photoUrl":"","userId":"18068657964817083524"}},"outputId":"f8bbdb5e-e10f-4611-9501-bf8d97cad67b"},"source":["!pip install tfa-nightly\n","!pip install import-ipynb\n","import import_ipynb\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import scipy.io as sio\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","from tqdm import tqdm\n","from fastprogress import master_bar, progress_bar\n","%cd '/content/drive/MyDrive/LMSLoss'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tfa-nightly in /usr/local/lib/python3.6/dist-packages (0.12.0.dev20201208041358)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tfa-nightly) (2.7.1)\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n","/content/drive/MyDrive/LMSLoss\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x-0ymWlWKgRa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486375082,"user_tz":-420,"elapsed":7800,"user":{"displayName":"hi trum","photoUrl":"","userId":"18068657964817083524"}},"outputId":"6cb02c3d-8e05-440a-dbc5-d6c012dfac55"},"source":["%run UnetModel.ipynb\n","# %run MumfordLoss.ipynb\n","%run augment_data.ipynb\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_7\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 128, 128, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 128, 128, 64) 576         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 128, 128, 64) 256         conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","swish_51 (Swish)                (None, 128, 128, 64) 0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 128, 128, 64) 36864       swish_51[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 128, 128, 64) 256         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","swish_52 (Swish)                (None, 128, 128, 64) 0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","lambda_19 (Lambda)              (None, 1, 1, 64)     0           swish_52[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 1, 1, 16)     1040        lambda_19[0][0]                  \n","__________________________________________________________________________________________________\n","swish_53 (Swish)                (None, 1, 1, 16)     0           conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 1, 1, 64)     1088        swish_53[0][0]                   \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 1, 1, 64)     0           conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","output_block_1 (Multiply)       (None, 128, 128, 64) 0           activation_19[0][0]              \n","                                                                 swish_52[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 64)   0           output_block_1[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 64, 64, 128)  73728       max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 64, 64, 128)  512         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","swish_54 (Swish)                (None, 64, 64, 128)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 64, 64, 128)  147456      swish_54[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 64, 64, 128)  512         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","swish_55 (Swish)                (None, 64, 64, 128)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","lambda_20 (Lambda)              (None, 1, 1, 128)    0           swish_55[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 1, 1, 32)     4128        lambda_20[0][0]                  \n","__________________________________________________________________________________________________\n","swish_56 (Swish)                (None, 1, 1, 32)     0           conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 1, 1, 128)    4224        swish_56[0][0]                   \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 1, 1, 128)    0           conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","output_block_2 (Multiply)       (None, 64, 64, 128)  0           activation_20[0][0]              \n","                                                                 swish_55[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 128)  0           output_block_2[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 32, 32, 256)  294912      max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 32, 32, 256)  1024        conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","swish_57 (Swish)                (None, 32, 32, 256)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 32, 32, 256)  589824      swish_57[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 32, 32, 256)  1024        conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","swish_58 (Swish)                (None, 32, 32, 256)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","lambda_21 (Lambda)              (None, 1, 1, 256)    0           swish_58[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 1, 1, 64)     16448       lambda_21[0][0]                  \n","__________________________________________________________________________________________________\n","swish_59 (Swish)                (None, 1, 1, 64)     0           conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 1, 1, 256)    16640       swish_59[0][0]                   \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 1, 1, 256)    0           conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","output_block_3 (Multiply)       (None, 32, 32, 256)  0           activation_21[0][0]              \n","                                                                 swish_58[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0           output_block_3[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 16, 16, 512)  1179648     max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 16, 16, 512)  2048        conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","swish_60 (Swish)                (None, 16, 16, 512)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 16, 16, 512)  2359296     swish_60[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 16, 16, 512)  2048        conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","swish_61 (Swish)                (None, 16, 16, 512)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","lambda_22 (Lambda)              (None, 1, 1, 512)    0           swish_61[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 1, 1, 128)    65664       lambda_22[0][0]                  \n","__________________________________________________________________________________________________\n","swish_62 (Swish)                (None, 1, 1, 128)    0           conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 1, 1, 512)    66048       swish_62[0][0]                   \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 1, 1, 512)    0           conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","output_block_4 (Multiply)       (None, 16, 16, 512)  0           activation_22[0][0]              \n","                                                                 swish_61[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 512)    0           output_block_4[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 8, 8, 512)    2359296     max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 8, 8, 512)    2048        conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","swish_63 (Swish)                (None, 8, 8, 512)    0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 8, 8, 512)    2359296     swish_63[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 8, 8, 512)    2048        conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","swish_64 (Swish)                (None, 8, 8, 512)    0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","lambda_23 (Lambda)              (None, 1, 1, 512)    0           swish_64[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 1, 1, 128)    65664       lambda_23[0][0]                  \n","__________________________________________________________________________________________________\n","swish_65 (Swish)                (None, 1, 1, 128)    0           conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 1, 1, 512)    66048       swish_65[0][0]                   \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 1, 1, 512)    0           conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","output_block_5 (Multiply)       (None, 8, 8, 512)    0           activation_23[0][0]              \n","                                                                 swish_64[0][0]                   \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           output_block_5[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 1, 1, 128)    65536       average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 1, 1, 128)    512         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 8, 8, 128)    65536       output_block_5[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 8, 8, 128)    589824      output_block_5[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 8, 8, 128)    1638400     output_block_5[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 8, 8, 128)    3211264     output_block_5[0][0]             \n","__________________________________________________________________________________________________\n","swish_66 (Swish)                (None, 1, 1, 128)    0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 8, 8, 128)    512         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 8, 8, 128)    512         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 8, 8, 128)    512         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 128)    0           swish_66[0][0]                   \n","__________________________________________________________________________________________________\n","swish_68 (Swish)                (None, 8, 8, 128)    0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","swish_70 (Swish)                (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","swish_72 (Swish)                (None, 8, 8, 128)    0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","swish_74 (Swish)                (None, 8, 8, 128)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","lambda_24 (Lambda)              (None, 1, 1, 128)    0           up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","lambda_25 (Lambda)              (None, 1, 1, 128)    0           swish_68[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_26 (Lambda)              (None, 1, 1, 128)    0           swish_70[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_27 (Lambda)              (None, 1, 1, 128)    0           swish_72[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_28 (Lambda)              (None, 1, 1, 128)    0           swish_74[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 1, 1, 32)     4128        lambda_24[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 1, 1, 32)     4128        lambda_25[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 1, 1, 32)     4128        lambda_26[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 1, 1, 32)     4128        lambda_27[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 1, 1, 32)     4128        lambda_28[0][0]                  \n","__________________________________________________________________________________________________\n","swish_67 (Swish)                (None, 1, 1, 32)     0           conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","swish_69 (Swish)                (None, 1, 1, 32)     0           conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","swish_71 (Swish)                (None, 1, 1, 32)     0           conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","swish_73 (Swish)                (None, 1, 1, 32)     0           conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","swish_75 (Swish)                (None, 1, 1, 32)     0           conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 1, 1, 128)    4224        swish_67[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 1, 1, 128)    4224        swish_69[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 1, 1, 128)    4224        swish_71[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 1, 1, 128)    4224        swish_73[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 1, 1, 128)    4224        swish_75[0][0]                   \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 1, 1, 128)    0           conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 1, 1, 128)    0           conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 1, 1, 128)    0           conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 1, 1, 128)    0           conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 1, 1, 128)    0           conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_14 (Multiply)          (None, 8, 8, 128)    0           activation_24[0][0]              \n","                                                                 up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","multiply_15 (Multiply)          (None, 8, 8, 128)    0           activation_25[0][0]              \n","                                                                 swish_68[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_16 (Multiply)          (None, 8, 8, 128)    0           activation_26[0][0]              \n","                                                                 swish_70[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_17 (Multiply)          (None, 8, 8, 128)    0           activation_27[0][0]              \n","                                                                 swish_72[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_18 (Multiply)          (None, 8, 8, 128)    0           activation_28[0][0]              \n","                                                                 swish_74[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 16, 16, 512)  2359296     output_block_4[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 8, 8, 640)    0           multiply_14[0][0]                \n","                                                                 multiply_15[0][0]                \n","                                                                 multiply_16[0][0]                \n","                                                                 multiply_17[0][0]                \n","                                                                 multiply_18[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 16, 16, 512)  2048        conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 8, 8, 128)    81920       concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","swish_78 (Swish)                (None, 16, 16, 512)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 8, 8, 128)    512         conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 16, 16, 512)  2359296     swish_78[0][0]                   \n","__________________________________________________________________________________________________\n","swish_76 (Swish)                (None, 8, 8, 128)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 16, 16, 512)  2048        conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_29 (Lambda)              (None, 1, 1, 128)    0           swish_76[0][0]                   \n","__________________________________________________________________________________________________\n","swish_79 (Swish)                (None, 16, 16, 512)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 1, 1, 32)     4128        lambda_29[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_30 (Lambda)              (None, 1, 1, 512)    0           swish_79[0][0]                   \n","__________________________________________________________________________________________________\n","swish_77 (Swish)                (None, 1, 1, 32)     0           conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 1, 1, 128)    65664       lambda_30[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 1, 1, 128)    4224        swish_77[0][0]                   \n","__________________________________________________________________________________________________\n","swish_80 (Swish)                (None, 1, 1, 128)    0           conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 1, 1, 128)    0           conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 1, 1, 512)    66048       swish_80[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_19 (Multiply)          (None, 8, 8, 128)    0           activation_29[0][0]              \n","                                                                 swish_76[0][0]                   \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 1, 1, 512)    0           conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 512)  262656      multiply_19[0][0]                \n","__________________________________________________________________________________________________\n","multiply_20 (Multiply)          (None, 16, 16, 512)  0           activation_30[0][0]              \n","                                                                 swish_79[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_transpose_4[0][0]         \n","                                                                 multiply_20[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 16, 16, 512)  4718592     concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 16, 16, 512)  2048        conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 32, 32, 256)  589824      output_block_3[0][0]             \n","__________________________________________________________________________________________________\n","swish_81 (Swish)                (None, 16, 16, 512)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 32, 32, 256)  1024        conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 16, 16, 512)  2359296     swish_81[0][0]                   \n","__________________________________________________________________________________________________\n","swish_84 (Swish)                (None, 32, 32, 256)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 16, 16, 512)  2048        conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 32, 32, 256)  589824      swish_84[0][0]                   \n","__________________________________________________________________________________________________\n","swish_82 (Swish)                (None, 16, 16, 512)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 32, 32, 256)  1024        conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_31 (Lambda)              (None, 1, 1, 512)    0           swish_82[0][0]                   \n","__________________________________________________________________________________________________\n","swish_85 (Swish)                (None, 32, 32, 256)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 1, 1, 128)    65664       lambda_31[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_32 (Lambda)              (None, 1, 1, 256)    0           swish_85[0][0]                   \n","__________________________________________________________________________________________________\n","swish_83 (Swish)                (None, 1, 1, 128)    0           conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_120 (Conv2D)             (None, 1, 1, 64)     16448       lambda_32[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 1, 1, 512)    66048       swish_83[0][0]                   \n","__________________________________________________________________________________________________\n","swish_86 (Swish)                (None, 1, 1, 64)     0           conv2d_120[0][0]                 \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 1, 1, 512)    0           conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_121 (Conv2D)             (None, 1, 1, 256)    16640       swish_86[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_21 (Multiply)          (None, 16, 16, 512)  0           activation_31[0][0]              \n","                                                                 swish_82[0][0]                   \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 1, 1, 256)    0           conv2d_121[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 256)  524544      multiply_21[0][0]                \n","__________________________________________________________________________________________________\n","multiply_22 (Multiply)          (None, 32, 32, 256)  0           activation_32[0][0]              \n","                                                                 swish_85[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_5[0][0]         \n","                                                                 multiply_22[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_122 (Conv2D)             (None, 32, 32, 256)  1179648     concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 32, 32, 256)  1024        conv2d_122[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 64, 64, 128)  147456      output_block_2[0][0]             \n","__________________________________________________________________________________________________\n","swish_87 (Swish)                (None, 32, 32, 256)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 64, 64, 128)  512         conv2d_126[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_123 (Conv2D)             (None, 32, 32, 256)  589824      swish_87[0][0]                   \n","__________________________________________________________________________________________________\n","swish_90 (Swish)                (None, 64, 64, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 32, 32, 256)  1024        conv2d_123[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 64, 64, 128)  147456      swish_90[0][0]                   \n","__________________________________________________________________________________________________\n","swish_88 (Swish)                (None, 32, 32, 256)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 64, 64, 128)  512         conv2d_127[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_33 (Lambda)              (None, 1, 1, 256)    0           swish_88[0][0]                   \n","__________________________________________________________________________________________________\n","swish_91 (Swish)                (None, 64, 64, 128)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_124 (Conv2D)             (None, 1, 1, 64)     16448       lambda_33[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_34 (Lambda)              (None, 1, 1, 128)    0           swish_91[0][0]                   \n","__________________________________________________________________________________________________\n","swish_89 (Swish)                (None, 1, 1, 64)     0           conv2d_124[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 1, 1, 32)     4128        lambda_34[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_125 (Conv2D)             (None, 1, 1, 256)    16640       swish_89[0][0]                   \n","__________________________________________________________________________________________________\n","swish_92 (Swish)                (None, 1, 1, 32)     0           conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 1, 1, 256)    0           conv2d_125[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 1, 1, 128)    4224        swish_92[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_23 (Multiply)          (None, 32, 32, 256)  0           activation_33[0][0]              \n","                                                                 swish_88[0][0]                   \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 1, 1, 128)    0           conv2d_129[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 128)  131200      multiply_23[0][0]                \n","__________________________________________________________________________________________________\n","multiply_24 (Multiply)          (None, 64, 64, 128)  0           activation_34[0][0]              \n","                                                                 swish_91[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_6[0][0]         \n","                                                                 multiply_24[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_130 (Conv2D)             (None, 64, 64, 128)  294912      concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 64, 64, 128)  512         conv2d_130[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_134 (Conv2D)             (None, 128, 128, 64) 36864       output_block_1[0][0]             \n","__________________________________________________________________________________________________\n","swish_93 (Swish)                (None, 64, 64, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 128, 128, 64) 256         conv2d_134[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_131 (Conv2D)             (None, 64, 64, 128)  147456      swish_93[0][0]                   \n","__________________________________________________________________________________________________\n","swish_96 (Swish)                (None, 128, 128, 64) 0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 64, 64, 128)  512         conv2d_131[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_135 (Conv2D)             (None, 128, 128, 64) 36864       swish_96[0][0]                   \n","__________________________________________________________________________________________________\n","swish_94 (Swish)                (None, 64, 64, 128)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 128, 128, 64) 256         conv2d_135[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_35 (Lambda)              (None, 1, 1, 128)    0           swish_94[0][0]                   \n","__________________________________________________________________________________________________\n","swish_97 (Swish)                (None, 128, 128, 64) 0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_132 (Conv2D)             (None, 1, 1, 32)     4128        lambda_35[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_36 (Lambda)              (None, 1, 1, 64)     0           swish_97[0][0]                   \n","__________________________________________________________________________________________________\n","swish_95 (Swish)                (None, 1, 1, 32)     0           conv2d_132[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_136 (Conv2D)             (None, 1, 1, 16)     1040        lambda_36[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_133 (Conv2D)             (None, 1, 1, 128)    4224        swish_95[0][0]                   \n","__________________________________________________________________________________________________\n","swish_98 (Swish)                (None, 1, 1, 16)     0           conv2d_136[0][0]                 \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 1, 1, 128)    0           conv2d_133[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_137 (Conv2D)             (None, 1, 1, 64)     1088        swish_98[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_25 (Multiply)          (None, 64, 64, 128)  0           activation_35[0][0]              \n","                                                                 swish_94[0][0]                   \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 1, 1, 64)     0           conv2d_137[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 64) 32832       multiply_25[0][0]                \n","__________________________________________________________________________________________________\n","multiply_26 (Multiply)          (None, 128, 128, 64) 0           activation_36[0][0]              \n","                                                                 swish_97[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_7[0][0]         \n","                                                                 multiply_26[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_138 (Conv2D)             (None, 128, 128, 64) 73728       concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 128, 128, 64) 256         conv2d_138[0][0]                 \n","__________________________________________________________________________________________________\n","swish_99 (Swish)                (None, 128, 128, 64) 0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_139 (Conv2D)             (None, 128, 128, 64) 36864       swish_99[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 128, 128, 64) 256         conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","swish_100 (Swish)               (None, 128, 128, 64) 0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","lambda_37 (Lambda)              (None, 1, 1, 64)     0           swish_100[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_140 (Conv2D)             (None, 1, 1, 16)     1040        lambda_37[0][0]                  \n","__________________________________________________________________________________________________\n","swish_101 (Swish)               (None, 1, 1, 16)     0           conv2d_140[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_141 (Conv2D)             (None, 1, 1, 64)     1088        swish_101[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 1, 1, 64)     0           conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","multiply_27 (Multiply)          (None, 128, 128, 64) 0           activation_37[0][0]              \n","                                                                 swish_100[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_142 (Conv2D)             (None, 128, 128, 1)  577         multiply_27[0][0]                \n","__________________________________________________________________________________________________\n","sigmoid (Activation)            (None, 128, 128, 1)  0           conv2d_142[0][0]                 \n","==================================================================================================\n","Total params: 32,410,257\n","Trainable params: 32,395,153\n","Non-trainable params: 15,104\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tGhKGmE85XcU"},"source":["import keras.backend as K\n","\n","def dice_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average dice coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    summation = K.sum(y_true + y_pred, axis=axes)\n","    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n","\n","def jaccard_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average jaccard coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    union = K.sum(y_true + y_pred, axis=axes) - intersection\n","    return K.mean( (intersection + smooth) / (union + smooth), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muwmP1U46HCr"},"source":["x = np.asarray(np.load('./dataACDCA/x_crop_128.npy'),np.float32)\n","y = np.load('./dataACDCA/y_crop_128.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uTTy0-rf7PIr"},"source":["np.random.seed(123)\n","len_dev = x.shape[0]//5\n","len_train = x.shape[0] - len_dev\n","rand_index = np.random.permutation(x.shape[0])\n","x_test = x[rand_index[:len_dev]]\n","y_test = y[rand_index[:len_dev]]\n","x_train = x[rand_index[len_dev:]]\n","y_train = y[rand_index[len_dev:]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vM3s3hxw6BKk"},"source":["# plt.figure(1)\n","# label_endo = tf.where(y_test == 2.0, 1.0, 0.0)\n","# label_epi =  tf.where(y_test == 1.0, 1.0, 0.0) + label_endo\n","# plt.subplot(131),plt.imshow(x[102][...,0],cmap='gray')\n","# plt.subplot(132),plt.imshow(label_epi[102][...,0],cmap='gray')\n","# plt.subplot(133),plt.imshow(y_test[102][...,0],cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYYo85QXKoMa"},"source":["BATCH_SIZE = 32\n","buffer_size = x_train.shape[0]\n","\n","@tf.function\n","def gen_image(image,mask):\n","  # image, mask = brightness(image,mask)\n","  #image, mask = saturation(image,mask)\n","  image, mask = flip(image,mask)\n","  image, mask = rotate_image(image,mask)\n","  image, mask = normalize(image, mask)\n","  return image, mask\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(buffer_size).map(gen_image).batch(BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test)).map(normalize).batch(BATCH_SIZE*2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3FWzlxY49Jy"},"source":["class MSLoss_vs2():\n","  def levelsetLoss(self,target, output):\n","    loss = 0.0\n","    for ich in range(target.shape[3]):\n","        target_ = target[...,ich:ich+1]    \n","        pcentroid = tf.reduce_sum(target_ * output, (1,2),keepdims=True)/tf.reduce_sum(output, (1,2),keepdims = True)   \n","        plevel = target_ - pcentroid\n","        pLoss = plevel * plevel * output\n","        loss += tf.reduce_sum(pLoss)\n","    return loss\n","      \n","  def activeContourLoss(self,y_true,y_pred,outDim =3,smooth=0.001):     \n","    yTrueOnehot = tf.one_hot(tf.squeeze(tf.cast(y_true,tf.uint8),axis=-1), depth = outDim)\n","    loss =  y_pred * (1-yTrueOnehot) + (1-y_pred)*yTrueOnehot\n","    return tf.reduce_mean(loss)\n","                    \n","  def gradientLoss(self,input,penalty = \"l1\"):\n","\n","    dH = tf.math.abs(input[:, 1:, :, :] - input[:, :-1, :, :])\n","    dW = tf.math.abs(input[:, :, 1:, :] - input[:, :, :-1, :])\n","    if penalty == \"l2\":\n","        dH = dH * dH\n","        dW = dW * dW\n","\n","    loss =  tf.reduce_sum(dH) +  tf.reduce_sum(dW)\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a09VmiqP1x_a"},"source":["class Mumford_Unet_vs2(MSLoss_vs2):\n","  def __init__(self,model):\n","    super().__init__()\n","    self.model = model\n","    self.optimizer = None\n","    self.trainData = None\n","    self.testData = None\n","    self.batch_size = BATCH_SIZE\n","    temp = x_train.shape[0] // self.batch_size\n","    self.train_step = temp + 1 if x_train.shape[0] % self.batch_size != 0 else temp\n","    self.learning_rate = 0.001\n","\n","  def optimizer_fc(self,op_type = \"adam\", op_param = 0.005):\n","    if op_type == 'adam':\n","      self.optimizer =  tf.keras.optimizers.Adam(op_param)\n","    elif op_type == \"nadam\":\n","      self.optimizer =  tf.keras.optimizers.Nadam(op_param)\n","\n","  def loss(self, image, output, trueLabel, alpha = 1e-3, beta = 0.001):\n","    # print('\\ractive loss: ',self.activeContourLoss(trueLabel, output),' leverset loss: ', self.levelsetLoss(image,output),'gradient loss: ', self.gradientLoss(output), end=\"\")\n","    return alpha * ( self.levelsetLoss(image,output) + beta * self.gradientLoss(output)) + self.activeContourLoss(trueLabel, output)\n","    # return self.activeContourLoss(trueLabel, output)\n","\n","  def metrics(self,y_true,y_pred):\n","    output_standard = tf.expand_dims(tf.argmax(y_pred,axis=-1),axis = -1)\n","    output_endo = tf.where(output_standard == 2, 1.0, 0.0)\n","    output_epi =  tf.where(output_standard == 1, 1.0, 0.0) + output_endo\n","    label_endo = tf.where(y_true == 2, 1.0, 0.0)\n","    label_epi =  tf.where(y_true == 1, 1.0, 0.0) + label_endo\n","\n","    dice_coef_endo = dice_coef(label_endo, output_endo)\n","    dice_coef_epi = dice_coef(label_epi, output_epi)\n","    jaccards_coef_endo = jaccard_coef(label_endo, output_endo)\n","    jaccards_coef_epi = jaccard_coef(label_epi, output_epi)\n","    return dice_coef_endo, dice_coef_epi, jaccards_coef_endo, jaccards_coef_epi\n","\n","  def evaluateTest(self,testDataset):\n","    test_dices_endo =  []\n","    test_dices_epi = []\n","    test_jaccards_endo =  []\n","    test_jaccards_epi = []\n","    for xBatchTest, yBatchTest in testDataset:\n","      yPredBatchTest = self.model(xBatchTest, training = False)\n","      diceEndoTest, diceEpiTest, jaccardEndoTest, jaccardEpiTest =  self.metrics(yBatchTest, yPredBatchTest)\n","\n","      test_dices_endo.append(diceEndoTest)\n","      test_dices_epi.append(diceEpiTest)\n","      test_jaccards_endo.append(jaccardEndoTest)\n","      test_jaccards_epi.append(jaccardEpiTest)\n","    return np.mean(test_dices_endo), np.mean(test_dices_epi), np.mean(test_jaccards_endo), np.mean(test_jaccards_epi)\n","    \n","  def epoch_training(self,model,optimizer, trainDataset, testDataset, mb, stepTrain, alpha_loss, beta_loss):\n","    train_losses = []\n","    train_dices_endo =  []\n","    train_dices_epi = []\n","    train_jaccards_endo =  []\n","    train_jaccards_epi = []\n","\n","    trainDataset = iter(trainDataset)  \n","    \n","    for _ in progress_bar(range(stepTrain),parent = mb):   \n","      image, y_true = next(trainDataset)\n","      with tf.GradientTape() as tape:\n","        y_pred = self.model(image, training = True)\n","        total_loss  =  self.loss(image, y_pred, y_true, alpha_loss, beta_loss)\n","      grad  = tape.gradient(total_loss, self.model.trainable_variables)\n","      optimizer.apply_gradients(zip(grad,self.model.trainable_variables))\n","      # y_pred, total_loss = self.step(image, y_true)\n","      diceEndoTrain, diceEpiTrain, jaccardEndoTrain, jaccardEpiTrain =  self.metrics(y_true, y_pred)\n","\n","      mb.child.comment = 'Train loss {:.4f}'.format(total_loss)\n","\n","      train_losses.append(total_loss)\n","      train_dices_endo.append(diceEndoTrain)\n","      train_dices_epi.append(diceEpiTrain)\n","      train_jaccards_endo.append(jaccardEndoTrain)\n","      train_jaccards_epi.append(jaccardEpiTrain)\n","\n","    trainLossMean = np.mean(train_losses)\n","    trainDiceEndoMean = np.mean(train_dices_endo)\n","    trainJaccardEndoMean = np.mean(train_jaccards_endo)\n","    trainDiceEpiMean = np.mean(train_dices_epi)\n","    trainJaccardEpiMean = np.mean(train_jaccards_epi)\n","\n","    testDiceEndoMean, testDiceEpiMean, _, _ = self.evaluateTest(testDataset)\n","\n","    return trainLossMean, trainDiceEndoMean, trainDiceEpiMean, testDiceEndoMean, testDiceEpiMean\n","\n","\n","  def train(self,num_epoch, reduceLrEpoch=10 , earlyStoping=22, minLr=1e-5, alpha_loss= 1e-6, beta_loss = 1,checkpoint_prefix = \"./weightAlpha(1e-6)/ckpt_{score:.4f}.h5\"):\n","    mb = master_bar(range(num_epoch))\n","    epochs_list = []\n","    history = dict()\n","    training_losses = []\n","    trainDiceEndo_list = []\n","    trainDiceEpi_list = []\n","    testDiceEndo_list = []\n","    testDiceEpi_list = []\n","    # learningRate_list = []\n","    best_score  = 0\n","    count = 0\n","    for epoch in mb:\n","      count += 1\n","      epochs_list.append(epoch+1)\n","\n","      trainLoss, trainDiceEndo, trainDiceEpi, testDiceEndo, testDiceEpi  \\\n","      = self.epoch_training(self.model, self.optimizer, self.trainData, self.testData, mb, self.train_step, alpha_loss, beta_loss)\n","\n","      mb.write('Finish train epoch {} with loss {:.4f} trainDiceEndo: {:.2f}, trainDiceEpi: {:.2f}, testDiceEndo: {:.2f},\\\n","      testDiceEpi: {:.2f}'.format(epoch+1, trainLoss, trainDiceEndo, trainDiceEpi, testDiceEndo, testDiceEpi ))\n","\n","      training_losses.append(trainLoss)\n","      trainDiceEndo_list.append(trainDiceEndo)\n","      trainDiceEpi_list.append(trainDiceEpi)\n","      testDiceEndo_list.append(testDiceEndo)\n","      testDiceEpi_list.append(testDiceEpi)\n","      # learningRate_list.append(self.learning_rate)\n","\n","      if count % reduceLrEpoch ==0 :\n","        self.learning_rate = self.learning_rate * 0.5\n","        if self.learning_rate < minLr:\n","          self.learning_rate = minLr\n","        print('learning rate is set to : ',self.learning_rate)\n","        self.optimizer.learning_rate.assign(self.learning_rate )\n","    \n","      mb.update_graph([[epochs_list, training_losses]], [0,num_epoch], [0,0.1])\n","      if count == earlyStoping :\n","        break\n","      ### Check point here ###\n","      ### Check point follow testDiceEpi ###\n","      if best_score < testDiceEndo:\n","          count = 0\n","          mb.write(\">>> Improved Dice-score ENDO from {:.4f} to {:.4f}\".format(best_score, testDiceEndo))\n","          best_score = testDiceEndo\n","          self.model.save_weights(checkpoint_prefix.format(score=best_score))\n","    history['epoch'] = epochs_list\n","    history['train_loss'] = training_losses\n","    history['train_dice_endo'] = trainDiceEndo_list\n","    history['train_dice_epi'] = trainDiceEpi_list\n","    history['test_dice_endo'] = testDiceEndo_list\n","    history['test_dice_epi'] = testDiceEpi_list\n","    # history['lr'] = learningRate_list\n","    return history "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHQGURfkKvj4"},"source":["S = seg_net()\n","nhat = Mumford_Unet_vs2(S)\n","nhat.learning_rate = 0.001\n","nhat.trainData = train_dataset\n","nhat.testData = test_dataset\n","nhat.optimizer_fc(op_type = \"nadam\", op_param=nhat.learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ggufsOvKyRR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1607490218761,"user_tz":-420,"elapsed":3851439,"user":{"displayName":"hi trum","photoUrl":"","userId":"18068657964817083524"}},"outputId":"fa102945-8892-46af-a01e-fe00d663de48"},"source":["history = nhat.train(200,alpha_loss=1e-7,beta_loss=1e-2,checkpoint_prefix=\"./weightACDCA_MS/ckpt_{score:.4f}.h5\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='117' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      58.50% [117/200 1:03:29<45:02]\n","    </div>\n","    \n","Finish train epoch 1 with loss 0.1733 trainDiceEndo: 0.27, trainDiceEpi: 0.29, testDiceEndo: 0.09,      testDiceEpi: 0.17<p>>>> Improved Dice-score ENDO from 0.0000 to 0.0885<p>Finish train epoch 2 with loss 0.0462 trainDiceEndo: 0.53, trainDiceEpi: 0.55, testDiceEndo: 0.07,      testDiceEpi: 0.39<p>Finish train epoch 3 with loss 0.0308 trainDiceEndo: 0.67, trainDiceEpi: 0.70, testDiceEndo: 0.46,      testDiceEpi: 0.59<p>>>> Improved Dice-score ENDO from 0.0885 to 0.4638<p>Finish train epoch 4 with loss 0.0226 trainDiceEndo: 0.74, trainDiceEpi: 0.77, testDiceEndo: 0.68,      testDiceEpi: 0.75<p>>>> Improved Dice-score ENDO from 0.4638 to 0.6784<p>Finish train epoch 5 with loss 0.0192 trainDiceEndo: 0.78, trainDiceEpi: 0.81, testDiceEndo: 0.74,      testDiceEpi: 0.80<p>>>> Improved Dice-score ENDO from 0.6784 to 0.7449<p>Finish train epoch 6 with loss 0.0158 trainDiceEndo: 0.81, trainDiceEpi: 0.84, testDiceEndo: 0.78,      testDiceEpi: 0.80<p>>>> Improved Dice-score ENDO from 0.7449 to 0.7756<p>Finish train epoch 7 with loss 0.0146 trainDiceEndo: 0.83, trainDiceEpi: 0.85, testDiceEndo: 0.78,      testDiceEpi: 0.84<p>>>> Improved Dice-score ENDO from 0.7756 to 0.7844<p>Finish train epoch 8 with loss 0.0130 trainDiceEndo: 0.85, trainDiceEpi: 0.87, testDiceEndo: 0.85,      testDiceEpi: 0.86<p>>>> Improved Dice-score ENDO from 0.7844 to 0.8453<p>Finish train epoch 9 with loss 0.0123 trainDiceEndo: 0.86, trainDiceEpi: 0.88, testDiceEndo: 0.86,      testDiceEpi: 0.88<p>>>> Improved Dice-score ENDO from 0.8453 to 0.8578<p>Finish train epoch 10 with loss 0.0125 trainDiceEndo: 0.85, trainDiceEpi: 0.87, testDiceEndo: 0.85,      testDiceEpi: 0.87<p>Finish train epoch 11 with loss 0.0115 trainDiceEndo: 0.86, trainDiceEpi: 0.89, testDiceEndo: 0.88,      testDiceEpi: 0.88<p>>>> Improved Dice-score ENDO from 0.8578 to 0.8766<p>Finish train epoch 12 with loss 0.0109 trainDiceEndo: 0.87, trainDiceEpi: 0.89, testDiceEndo: 0.88,      testDiceEpi: 0.89<p>Finish train epoch 13 with loss 0.0105 trainDiceEndo: 0.87, trainDiceEpi: 0.90, testDiceEndo: 0.85,      testDiceEpi: 0.88<p>Finish train epoch 14 with loss 0.0110 trainDiceEndo: 0.87, trainDiceEpi: 0.89, testDiceEndo: 0.86,      testDiceEpi: 0.89<p>Finish train epoch 15 with loss 0.0105 trainDiceEndo: 0.87, trainDiceEpi: 0.90, testDiceEndo: 0.85,      testDiceEpi: 0.89<p>Finish train epoch 16 with loss 0.0097 trainDiceEndo: 0.88, trainDiceEpi: 0.91, testDiceEndo: 0.88,      testDiceEpi: 0.89<p>>>> Improved Dice-score ENDO from 0.8766 to 0.8776<p>Finish train epoch 17 with loss 0.0099 trainDiceEndo: 0.88, trainDiceEpi: 0.90, testDiceEndo: 0.88,      testDiceEpi: 0.89<p>>>> Improved Dice-score ENDO from 0.8776 to 0.8847<p>Finish train epoch 18 with loss 0.0096 trainDiceEndo: 0.89, trainDiceEpi: 0.91, testDiceEndo: 0.88,      testDiceEpi: 0.89<p>Finish train epoch 19 with loss 0.0107 trainDiceEndo: 0.87, trainDiceEpi: 0.90, testDiceEndo: 0.79,      testDiceEpi: 0.82<p>Finish train epoch 20 with loss 0.0121 trainDiceEndo: 0.86, trainDiceEpi: 0.88, testDiceEndo: 0.84,      testDiceEpi: 0.64<p>Finish train epoch 21 with loss 0.0101 trainDiceEndo: 0.88, trainDiceEpi: 0.91, testDiceEndo: 0.88,      testDiceEpi: 0.90<p>Finish train epoch 22 with loss 0.0099 trainDiceEndo: 0.88, trainDiceEpi: 0.91, testDiceEndo: 0.89,      testDiceEpi: 0.89<p>>>> Improved Dice-score ENDO from 0.8847 to 0.8898<p>Finish train epoch 23 with loss 0.0091 trainDiceEndo: 0.89, trainDiceEpi: 0.92, testDiceEndo: 0.81,      testDiceEpi: 0.85<p>Finish train epoch 24 with loss 0.0092 trainDiceEndo: 0.89, trainDiceEpi: 0.92, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>>>> Improved Dice-score ENDO from 0.8898 to 0.8992<p>Finish train epoch 25 with loss 0.0089 trainDiceEndo: 0.89, trainDiceEpi: 0.92, testDiceEndo: 0.87,      testDiceEpi: 0.90<p>Finish train epoch 26 with loss 0.0088 trainDiceEndo: 0.90, trainDiceEpi: 0.92, testDiceEndo: 0.88,      testDiceEpi: 0.90<p>Finish train epoch 27 with loss 0.0088 trainDiceEndo: 0.89, trainDiceEpi: 0.92, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>>>> Improved Dice-score ENDO from 0.8992 to 0.9043<p>Finish train epoch 28 with loss 0.0084 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.88,      testDiceEpi: 0.91<p>Finish train epoch 29 with loss 0.0083 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.87,      testDiceEpi: 0.89<p>Finish train epoch 30 with loss 0.0083 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.85,      testDiceEpi: 0.86<p>Finish train epoch 31 with loss 0.0085 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.89,      testDiceEpi: 0.91<p>Finish train epoch 32 with loss 0.0083 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.88,      testDiceEpi: 0.91<p>Finish train epoch 33 with loss 0.0085 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.87,      testDiceEpi: 0.91<p>Finish train epoch 34 with loss 0.0086 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>Finish train epoch 35 with loss 0.0082 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.89,      testDiceEpi: 0.91<p>Finish train epoch 36 with loss 0.0085 trainDiceEndo: 0.90, trainDiceEpi: 0.92, testDiceEndo: 0.88,      testDiceEpi: 0.89<p>Finish train epoch 37 with loss 0.0082 trainDiceEndo: 0.90, trainDiceEpi: 0.93, testDiceEndo: 0.91,      testDiceEpi: 0.90<p>>>> Improved Dice-score ENDO from 0.9043 to 0.9070<p>Finish train epoch 38 with loss 0.0077 trainDiceEndo: 0.91, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>Finish train epoch 39 with loss 0.0077 trainDiceEndo: 0.91, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>Finish train epoch 40 with loss 0.0077 trainDiceEndo: 0.91, trainDiceEpi: 0.93, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 41 with loss 0.0075 trainDiceEndo: 0.92, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 42 with loss 0.0074 trainDiceEndo: 0.92, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 43 with loss 0.0075 trainDiceEndo: 0.91, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 44 with loss 0.0073 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 45 with loss 0.0074 trainDiceEndo: 0.92, trainDiceEpi: 0.94, testDiceEndo: 0.90,      testDiceEpi: 0.91<p>Finish train epoch 46 with loss 0.0075 trainDiceEndo: 0.91, trainDiceEpi: 0.94, testDiceEndo: 0.89,      testDiceEpi: 0.91<p>Finish train epoch 47 with loss 0.0073 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 48 with loss 0.0072 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 49 with loss 0.0070 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.88,      testDiceEpi: 0.90<p>Finish train epoch 50 with loss 0.0071 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9070 to 0.9133<p>Finish train epoch 51 with loss 0.0070 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.93<p>Finish train epoch 52 with loss 0.0070 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 53 with loss 0.0069 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 54 with loss 0.0069 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.90,      testDiceEpi: 0.92<p>Finish train epoch 55 with loss 0.0069 trainDiceEndo: 0.92, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 56 with loss 0.0069 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>>>> Improved Dice-score ENDO from 0.9133 to 0.9147<p>Finish train epoch 57 with loss 0.0069 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 58 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 59 with loss 0.0069 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9147 to 0.9149<p>Finish train epoch 60 with loss 0.0070 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 61 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 62 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 63 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 64 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 65 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 66 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 67 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 68 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9149 to 0.9177<p>Finish train epoch 69 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 70 with loss 0.0070 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 71 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 72 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 73 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 74 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 75 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 76 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9177 to 0.9188<p>Finish train epoch 77 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 78 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 79 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 80 with loss 0.0068 trainDiceEndo: 0.93, trainDiceEpi: 0.95, testDiceEndo: 0.92,      testDiceEpi: 0.92<p>Finish train epoch 81 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 82 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.92<p>Finish train epoch 83 with loss 0.0067 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 84 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 85 with loss 0.0066 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 86 with loss 0.0065 trainDiceEndo: 0.93, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 87 with loss 0.0065 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 88 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 89 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 90 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 91 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9188 to 0.9205<p>Finish train epoch 92 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 93 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 94 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 95 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 96 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>>>> Improved Dice-score ENDO from 0.9205 to 0.9213<p>Finish train epoch 97 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 98 with loss 0.0064 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 99 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 100 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 101 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.91,      testDiceEpi: 0.93<p>Finish train epoch 102 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 103 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 104 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 105 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 106 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 107 with loss 0.0063 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 108 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 109 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 110 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 111 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 112 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 113 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 114 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.96, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 115 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 116 with loss 0.0062 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>Finish train epoch 117 with loss 0.0061 trainDiceEndo: 0.94, trainDiceEpi: 0.97, testDiceEndo: 0.92,      testDiceEpi: 0.93<p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='48' class='' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [48/48 00:30<00:00 Train loss 0.0047]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeJ0lEQVR4nO3de5Bc5Xnn8e/Tl+m5aiSNBOiGJAyWERgDGstyjG1iEkcC28IBXGA7JhV2lVSZWrsc1lGKKkJwdtfEWZN4jc1CQYKxMTg4rJWyCMHBsmNzMSNZCAkEGoSERgh0nZHm3pdn/zhnhtYwo2lJc7pPj36fqqnpfs/bPc+cafVP73nPedvcHRERObUlKl2AiIhUnsJAREQUBiIiojAQEREUBiIigsJAREQoMQzMbLmZvWxm7Wa2epTtHzGzDWaWM7OrR2y73sy2hV/XT1ThIiIycWy86wzMLAm8Avw+0AE8B1zn7i8W9VkATAFuAta4+yNh+3SgDWgFHFgPLHH3QxP9i4iIyIkrZWSwFGh39+3uPgg8BKws7uDuO9x9E1AY8dg/AJ5w94NhADwBLJ+AukVEZAKlSugzB9hVdL8D+ECJzz/aY+eM7GRmq4BVAA0NDUve85730L63m1TCWDCjocQfJSJy6lq/fv1+d595oo8vJQwi5+53A3cDtLa2eltbG1fe+Wum1KX53p8srXB1IiLxZ2Y7T+bxpRwm2g3MK7o/N2wrxQk/1gy0bpKISHmUEgbPAeeY2UIzqwGuBdaU+PyPAx83s2lmNg34eNg2fmFmKAtERMpj3DBw9xxwI8Gb+EvAj9x9i5ndZmafAjCz95tZB3AN8H/NbEv42IPA1wgC5TngtrBtXAYUlAYiImVR0pyBu68F1o5ou6Xo9nMEh4BGe+x9wH3HW5hGBiJyPLLZLB0dHfT391e6lEjV1tYyd+5c0un0hD5vLCaQR2UaGYhI6To6OmhqamLBggWYWaXLiYS7c+DAATo6Oli4cOGEPndsl6NIWHCVmohIKfr7+2lpaZm0QQBgZrS0tEQy+oltGBims4lE5LhM5iAYEtXvGNswSCTQnIGISJnENwzMNGcgIlWjs7OT73znO8f9uMsvv5zOzs4IKjo+sQ0DgIKyQESqxFhhkMvljvm4tWvXMnXq1KjKKllszyZKmGkCWUSqxurVq3n11Ve58MILSafT1NbWMm3aNLZu3corr7zClVdeya5du+jv7+dLX/oSq1atAmDBggW0tbXR3d3NihUruOSSS3jqqaeYM2cOP/nJT6irqytL/bENAy1HISIn6q//dQsvvnF4Qp9z8ewp/NUnzxtz+9e//nU2b97Mxo0bWbduHVdccQWbN28ePgX0vvvuY/r06fT19fH+97+fq666ipaWlqOeY9u2bfzwhz/knnvu4TOf+Qw//vGP+fznPz+hv8dYYhsGuuhMRKrZ0qVLj7oW4Fvf+haPPvooALt27WLbtm3vCIOFCxdy4YUXArBkyRJ27NhRtnpjGwZajkJETtSx/gdfLg0Nby+/v27dOn72s5/x9NNPU19fz6WXXjrqtQKZTGb4djKZpK+vryy1QownkE0jAxGpIk1NTRw5cmTUbV1dXUybNo36+nq2bt3KM888U+bqxhffkYGWoxCRKtLS0sKHPvQhzj//fOrq6jj99NOHty1fvpy77rqLc889l0WLFrFs2bIKVjq62IZBYvJfSCgik8yDDz44ansmk+Gxxx4bddvQvMCMGTPYvHnzcPtNN9004fUdS2wPE+miMxGR8oltGASHiSpdhYjIqSHGYaCF6kTk+JwK7xlR/Y7xDQO0UJ2IlK62tpYDBw5M6kAY+jyD2traCX/uGE8gazkKESnd3Llz6ejoYN++fZUuJVJDn3Q20WIbBjq1VESORzqdnvBP/zqVxPYwkZajEBEpn9iGgZajEBEpn/iGgUYGIiJlE9swSGgJaxGRsoltGOiiMxGR8oltGASnlioNRETKIbZhoJGBiEj5xDgMNIEsIlIu8Q0DNIEsIlIusQ0DLUchIlI+sQ0DLUchIlI+sQ0DLUchIlI+sQ0D0MhARKRcYhsGGhmIiJRPjMNAZxOJiJRLbMNAF52JiJRPSWFgZsvN7GUzazez1aNsz5jZw+H2Z81sQdieNrP7zewFM3vJzP6y5MK0HIWISNmMGwZmlgTuBFYAi4HrzGzxiG43AIfc/WzgDuD2sP0aIOPu7wWWAH86FBTj0shARKRsShkZLAXa3X27uw8CDwErR/RZCdwf3n4EuMzMDHCgwcxSQB0wCBwuqTAzNDAQESmPUsJgDrCr6H5H2DZqH3fPAV1AC0Ew9AB7gNeBv3P3gyN/gJmtMrM2M2sb+jBrfdKZiEj5RD2BvBTIA7OBhcCfm9lZIzu5+93u3ururTNnzgwK03IUIiJlU0oY7AbmFd2fG7aN2ic8JNQMHAA+C/ybu2fdfS/wa6C1lMK0HIWISPmUEgbPAeeY2UIzqwGuBdaM6LMGuD68fTXwpAcXCbwOfAzAzBqAZcDWUgrTEtYiIuUzbhiEcwA3Ao8DLwE/cvctZnabmX0q7HYv0GJm7cBXgKHTT+8EGs1sC0Go/KO7byqpMBv++aX/NiIickJSpXRy97XA2hFttxTd7ic4jXTk47pHay+FEaRBwSFpJ/IMIiJSqthegayRgYhI+cQ2DCwMA114JiISvRiHQZAGWpJCRCR6MQ6D4LuOEomIRC+2YZAYGhkoDEREIhfbMBg6gUgXnomIRC+2YTA8MqhwHSIip4LYhsHbZxMpDkREohbjMAhHBoUKFyIicgqIbRgMX3SmA0UiIpGLbRi8PYFc0TJERE4JsQ2DRGLo1FKlgYhI1GIbBhoZiIiUT3zDQMtRiIiUTYzDIPiuo0QiItGLbRhoOQoRkfKJbRhoOQoRkfKJbRgMjQwUBiIi0YttGGjOQESkfGIcBpozEBEpl9iGgZajEBEpn9iGgT4DWUSkfGIbBm+fWqo0EBGJWmzDYIhGBiIi0YttGAyNDPRZZyIi0YttGGjOQESkfGIbBrroTESkfGIcBsF3ZYGISPRiGwZDqxNpZCAiEr3YhoFGBiIi5RPbMNByFCIi5RPbMNByFCIi5RPbMNCppSIi5RPjMNByFCIi5VJSGJjZcjN72czazWz1KNszZvZwuP1ZM1tQtO0CM3vazLaY2QtmVlvSzwy/a2QgIhK9ccPAzJLAncAKYDFwnZktHtHtBuCQu58N3AHcHj42BXwf+DN3Pw+4FMiWVJiWoxARKZtSRgZLgXZ33+7ug8BDwMoRfVYC94e3HwEus+A4z8eBTe7+PIC7H3D3fEmFDV+BXEpvERE5GaWEwRxgV9H9jrBt1D7ungO6gBbg3YCb2eNmtsHMvjraDzCzVWbWZmZt+/btC9uCbQWlgYhI5KKeQE4BlwCfC79/2swuG9nJ3e9291Z3b505cyZQ9BnIERcoIiKlhcFuYF7R/blh26h9wnmCZuAAwSjil+6+3917gbXAxaUUZlqOQkSkbEoJg+eAc8xsoZnVANcCa0b0WQNcH96+GnjSg3NCHwfea2b1YUh8FHixpMI0fywiUjap8Tq4e87MbiR4Y08C97n7FjO7DWhz9zXAvcADZtYOHCQIDNz9kJl9kyBQHFjr7j8tpTDTBLKISNmMGwYA7r6W4BBPcdstRbf7gWvGeOz3CU4vPS5ajkJEpHxifAVy8F0jAxGR6MU4DLQchYhIucQ2DBJawlpEpGxiGwZvr02kNBARiVpsw0AjAxGR8oltGLw9gaw0EBGJWuzDQFEgIhK9+IYBOptIRKRcYhsGibAyZYGISPRiGwZvL1RX4UJERE4BsQ0DLUchIlI+sQ0DLUchIlI+MQ4DTSCLiJRLbMNAF52JiJRPbMNAy1GIiJRPbMNAIwMRkfKJbRhoOQoRkfKJfRgoCkREohfjMNDZRCIi5RLbMBi+6ExZICISudiGgZajEBEpn9iGQUITyCIiZRPbMBieM6hwHSIip4IYh0HwXRPIIiLRi20YpMMPNMjmFQYiIlGLbRjUZ5IA9A7kKlyJiMjkF9swSCcT1KQSdA8qDEREohbbMABozKTo0chARCRysQ6D+pokPQP5SpchIjLpxToMNDIQESmPWIdBQyZFj+YMREQiF/sw6NZhIhGRyMU6DBozSR0mEhEpg1iHQX2N5gxERMoh1mGgCWQRkfIoKQzMbLmZvWxm7Wa2epTtGTN7ONz+rJktGLH9TDPrNrObjqe4hkySnsG81icSEYnYuGFgZkngTmAFsBi4zswWj+h2A3DI3c8G7gBuH7H9m8Bjx1tcQyZFvuAM5ArH+1ARETkOpYwMlgLt7r7d3QeBh4CVI/qsBO4Pbz8CXGbhGtRmdiXwGrDleItrqEkB0K1DRSIikSolDOYAu4rud4Rto/Zx9xzQBbSYWSPwF8BfH+sHmNkqM2szs7Z9+/YNtzdkgjDQvIGISLSinkC+FbjD3buP1cnd73b3VndvnTlz5nB7Y7hyqZakEBGJVqqEPruBeUX354Zto/XpMLMU0AwcAD4AXG1mfwtMBQpm1u/u3y6luOGRga5CFhGJVClh8BxwjpktJHjTvxb47Ig+a4DrgaeBq4EnPTgF6MNDHczsVqC71CCAt8NAcwYiItEaNwzcPWdmNwKPA0ngPnffYma3AW3uvga4F3jAzNqBgwSBcdKGJpA1ZyAiEq1SRga4+1pg7Yi2W4pu9wPXjPMctx5vcQ3Dn3amOQMRkSjF/gpk0GEiEZGoxToMdGqpiEh5xDoM9DnIIiLlEeswAGio0TLWIiJRi38YZFKaQBYRiVjsw6Axk9IEsohIxGIfBvocZBGR6FVFGOhzkEVEohX/MNAEsohI5OIfBpkUvQoDEZFIxT4MNIEsIhK92IeBPgdZRCR6sQ+D+hp9DrKISNRiHwZarE5EJHqxD4PpDTUAHOwZrHAlIiKTV+zDYGZTBoB9RwYqXImIyOSlMBARkeoJg/3dCgMRkajEPgyaMikyqYRGBiIiEYp9GJgZMxozCgMRkQjFPgwgOFS0T4eJREQiUz1hoJGBiEhkFAYiIlIlYdCY4WDvILm8lqQQEYlCdYRBUwZ3XYUsIhKVqgkDgL06VCQiEomqCIMZjeFVyDqjSEQkElURBqdpSQoRkUhVRRgMjwwUBiIikaiKMKirSdKUSSkMREQiUhVhAMEksharExGJRtWEwYymDG929Ve6DBGRSalqwmDxrCm8uOewLjwTEYlA1YTBxfOn0TuYZ+ubRypdiojIpFNSGJjZcjN72czazWz1KNszZvZwuP1ZM1sQtv++ma03sxfC7x870UJb508DoG3HwRN9ChERGcO4YWBmSeBOYAWwGLjOzBaP6HYDcMjdzwbuAG4P2/cDn3T39wLXAw+caKGzp9Yxq7mW9a93nuhTiIjIGEoZGSwF2t19u7sPAg8BK0f0WQncH95+BLjMzMzdf+vub4TtW4A6M8ucaLFL5k9jvUYGIiITrpQwmAPsKrrfEbaN2sfdc0AX0DKiz1XABnd/x/mhZrbKzNrMrG3fvn1jFrJk/jTe6Ornjc6+EsoWEZFSlWUC2czOIzh09KejbXf3u9291d1bZ86cOebztM6fDsD6nYeiKFNE5JRVShjsBuYV3Z8bto3ax8xSQDNwILw/F3gU+IK7v3oyxZ47q4m6dFJhICIywUoJg+eAc8xsoZnVANcCa0b0WUMwQQxwNfCku7uZTQV+Cqx291+fbLGpZIIL501VGIiITLBxwyCcA7gReBx4CfiRu28xs9vM7FNht3uBFjNrB74CDJ1+eiNwNnCLmW0Mv047mYKXzJ/Gi3sO0zOQO5mnERGRIqlSOrn7WmDtiLZbim73A9eM8ri/Af7mJGs8ypIF08j/3Hm+o5PfedeMiXxqEZFTVtVcgTzk4nnBxWfrd+hQkYjIRKm6MGiuT/Pu0xtp07yBiMiEqbowgGDeYMPrhygUvNKliIhMClUZBh981wyO9Od4bPOblS5FRGRSqMowuPz8Mzh31hT+x09fpHdQZxWJiJysqgyDVDLB11aexxtd/dz58/ZKlyMiUvWqMgwAWhdM58oLZ3Pvr15j7xF9ApqIyMmo2jAA+PLvvZts3rlr3fZKlyIiUtWqOgwWzGjg0xfN4QfP7mTvYY0OREROVFWHAcB/+9g55AvOFx/cQPdAjv5snv5svtJliYhUlaoPgzNb6vn7ay9kw+udLP/7X3LRbU9w+T/8J4f7syf8nPu7BxjIKVBE5NRR9WEA8IkLZnPnZy9iRmOGT1wwi50He/nqP2/C/fgvSjvQPcDH/m4d//OnL0VQqYhIPE2KMABYfv4s/t8XP8Q3rnkff7F8Ef+25U3+12Nbj/sq5f/zZDuH+3P8y4bd9A1qdCAip4ZJEwbF/uuHz+Lzy87k7l9u5798r43dnX1s3NXJin/4T25ds2XMQ0A79vfw/Wd28r65zRwZyLH2hT1lrlxEpDImZRiYGV9beT5fW3kev9q2n9/9xjquuesp3jrczz89tYOrvvvUO65NKBScv1qzhXQywT1faGXhjAYebts1xk8QEZlcJmUYQBAIf/TBBaz775dyTetcPvm+2fz8zy/lni+0sn1fD5+751me39XJA8/sZN3Le/nuL17lF6/s4+YrzuW0KbVc0zqX37x2kK/8aCO/2ra/0r+OiEik7EQmWaPU2trqbW1tkf6MZ7Yf4I//8Tf0ZwtHtV9xwSy+fd1FmBmH+7PcumYL//HSXrr6snztyvP5o2XzI61LROREmdl6d2894cefimEAsOH1Q2ze3cUlZ89g295ufvt6J1/83XfRVJs+ql9/Ns+ND27gZy/tZXZzLd0DOT666DQ+ccEsLjpzKplUkv5sntOn1EZes4jIWBQGZZDNF7jjiVd4s6ufRMJ44sW36Oo7+jqGZWdNZ9VHzmLZWS3UpZN09mZp23mIgz0DfGBhCwBb3jjMS3sOk80X+Pyy+TTVpli/8xDnzW7mjGaFiYicOIVBBQzk8mzq6GJTRxfuzkCuwP1P7WDvkQFSCSOZMAZyhVEfm0wYCYOhM17z4Y0PntXCzVecy/lzmsv1a4jIJKIwiIn+bJ5nth/guR0HyeadmY0ZLpjbTEtjDU9vP0gqYZw/u5lzTm+kszfL957eAcDvvGsGv339EPc/vYODPYO0zp9OU22K3sE8qaRxxXtnsWT+NFLJBN39OXKFAufOmkJtOom7c7gvR1dflllTa0knJ+35ACIyDoXBJNHVl+XbT25jU0cXR/pz1NckOdgzyPb9Pe/om04aU+tr6O7P0Reuw5RMGPOn17PojCbeN28qi85oorN3kJpkkkVnNDGlNkVNKsGU2jRm0DuYxwxSiQTZfIFkwqhNJ4/6Of3ZPAd7BmlprCGTSr6jjlL1Duaor0md8ONFZHwnGwb6FxoTzXVpbr5i8VFt7s4Lu7vYeaCXbL5AU22afMHZuKuTrr5BGmpSnNFcS1Ntil0H+9i29whb3jh8zI8DTVgQHNn8O/8TUJtOMKMxQ1Ntmj1dfXT2BvMiNakE582ewozGDJlUgsFcgd7BPIO5Ai2NNdTVJOkdyDOtIc2Z0xuYVh8Ezp6ufp7cupdNHV2cNbOB985ppncwT6Hg1KaTLJ49hfkt9ew/MkA276STRn0mRUNNinTSKLhzpD/Hi3sOs797kDOn19HSkCGVNAayBRznjOY6GjNJ3IN92NKY4YwptdTVnHh4iZyKNDKYhPYdGeC1/T1Mb6ihP5vnlbeODL95H+wZJO9Oc11w1lQuXyCdTJArOJ29g+zvHuRwX5YzmmuZPbWOqfVpXtvXw+Y3uujszTKYK1CTSlBfkySdTHCgZ5C+wTz1NUkO9AxysGfwqFrOnzOFj757Jps6unhtfw+NmRTJhNE9kGPngd6Sfp/adILTmmp5o7OPXInLizRmUjTXpRnIFcjmCzTUJKlJJY6aqzncnyWZMGY0ZpjRWENzXRp3yBWcgVyevsE82bxTlw4eawZ16SS16STdAzkK7kytS5NMJCi4U3AnlUjQVBv8jgY0ZIIR2dB+y6QSpBJGItyeSBiphGFm4JAtBHNN6USCqfVpGmtT4HDalAxnn9ZU0u8upyaNDOQdZjZlmNmUGb5fzknpnoFgDqPgzozGzDsOPRU71DPIm4f7mdl09IijLxsEV8KM+pokc6fVkUoGh7N6B/JkC4XhOZM3Ovvpy+YxgkNt+44M8ObhfvZ3D3C4L0dNKkFN0ugeyJMrFDCCCxITZjTVpsgVCuw/MsiBniBAE2akkkYmlaQ+HKH0ZfP0DuYoeBC0fdk8TbUpDGP7vh7yBSeRgIQZ2VyBIwM5CgWn4AwfxjtZ175/Hl+/6oIJeS6R0SgMZEI1ZFI0ZEp7WU1rqGFaQ81RbS3H6J9OJmiuP3qSfNEZ6TF6x0Oh4GQLBWqSCQbzBfoHCxTcybvjDgV3cgUfXmF36CSAwVyBzt4s3QM5Egan6ToWiZjCQCRCiYSRSQSjo0wqeVwT8fOmR1WVyDvpXEQREVEYiIiIwkBERFAYiIgICgMREUFhICIiKAxERASFgYiIUGIYmNlyM3vZzNrNbPUo2zNm9nC4/VkzW1C07S/D9pfN7A8mrnQREZko44aBmSWBO4EVwGLgOjNbPKLbDcAhdz8buAO4PXzsYuBa4DxgOfCd8PlERCRGShkZLAXa3X27uw8CDwErR/RZCdwf3n4EuMzMLGx/yN0H3P01oD18PhERiZFS1iaaA+wqut8BfGCsPu6eM7MugjXH5gDPjHjsnJE/wMxWAavCuwNmtrmk6itrBrC/0kWUQHVOLNU5caqhRqieOhedzINjsVCdu98N3A1gZm0nsyZ3uajOiaU6J1Y11FkNNUJ11Xkyjy/lMNFuYF7R/blh26h9zCwFNAMHSnysiIhUWClh8BxwjpktNLMaggnhNSP6rAGuD29fDTzpwQLta4Brw7ONFgLnAL+ZmNJFRGSijHuYKJwDuBF4HEgC97n7FjO7DWhz9zXAvcADZtYOHCQIDMJ+PwJeBHLAF919vI9+uvvEf52yUp0TS3VOrGqosxpqhFOkzth9BrKIiJSfrkAWERGFgYiIxCwMxlv2olLMbJ6Z/dzMXjSzLWb2pbD9VjPbbWYbw6/LY1DrDjN7IaynLWybbmZPmNm28Pu0Cta3qGh/bTSzw2b25TjsSzO7z8z2Fl/nMta+s8C3wtfqJjO7uMJ1fsPMtoa1PGpmU8P2BWbWV7Rf76pwnWP+nSu1dM0YdT5cVOMOM9sYtldkfx7jPWjiXp/uHosvgsnpV4GzgBrgeWBxpesKa5sFXBzebgJeIVia41bgpkrXN6LWHcCMEW1/C6wOb68Gbq90nUV/8zeB+XHYl8BHgIuBzePtO+By4DHAgGXAsxWu8+NAKrx9e1GdC4r7xWB/jvp3Dv89PQ9kgIXhe0GyUnWO2P6/gVsquT+P8R40Ya/POI0MSln2oiLcfY+7bwhvHwFeYpQrqWOseLmQ+4ErK1hLscuAV919Z6ULAXD3XxKcDVdsrH23EvieB54BpprZrErV6e7/7u658O4zBNf0VNQY+3MsFVu65lh1mpkBnwF+WI5axnKM96AJe33GKQxGW/Yidm+4FqzIehHwbNh0YzgMu6+Sh1+KOPDvZrbegmU+AE539z3h7TeB0ytT2jtcy9H/yOK2L2HsfRfn1+ufEPyvcMhCM/utmf3CzD5cqaKKjPZ3juv+/DDwlrtvK2qr6P4c8R40Ya/POIVB7JlZI/Bj4Mvufhj4LvAu4EJgD8FwstIucfeLCVaZ/aKZfaR4owdjyIqfT2zBBYyfAv45bIrjvjxKXPbdsZjZzQTX9PwgbNoDnOnuFwFfAR40symVqo8q+DuPcB1H/4elovtzlPegYSf7+oxTGMR66QozSxP8EX7g7v8C4O5vuXve3QvAPcRgRVZ33x1+3ws8SlDTW0NDxPD73spVOGwFsMHd34J47svQWPsudq9XM/tj4BPA58I3BsLDLgfC2+sJjsW/u1I1HuPvHMf9mQL+EHh4qK2S+3O09yAm8PUZpzAoZdmLigiPG94LvOTu3yxqLz4G92mgoqutmlmDmTUN3SaYVNzM0cuFXA/8pDIVHuWo/3HFbV8WGWvfrQG+EJ61sQzoKhqul52ZLQe+CnzK3XuL2mda+BkiZnYWwZIw2ytT5TH/znFcuub3gK3u3jHUUKn9OdZ7EBP5+iz3rPg4M+aXE8ySvwrcXOl6iuq6hGD4tQnYGH5dDjwAvBC2rwFmVbjOswjOyHge2DK0DwmWE/8PYBvwM2B6hetsIFjIsLmoreL7kiCc9gBZgmOsN4y17wjO0rgzfK2+ALRWuM52gmPEQ6/Pu8K+V4WvhY3ABuCTFa5zzL8zcHO4P18GVlSyzrD9n4A/G9G3IvvzGO9BE/b61HIUIiISq8NEIiJSIQoDERFRGIiIiMJARERQGIiICAoDERFBYSAiIsD/BxZbDFtprEUBAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["learning rate is set to :  0.0005\n","learning rate is set to :  0.00025\n","learning rate is set to :  0.000125\n","learning rate is set to :  6.25e-05\n","learning rate is set to :  3.125e-05\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"dAaJBPn5q8K3"},"source":["sio.savemat('./weightACDCA_MS/historyACDCA_MS.mat',history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HoH74U16K0Ic"},"source":["nhat.model.load_weights('/content/drive/MyDrive/LMSLoss/weightACDCA_MS/ckpt_0.9213.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYlhJsqrbnqa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607490826584,"user_tz":-420,"elapsed":15302,"user":{"displayName":"hi trum","photoUrl":"","userId":"18068657964817083524"}},"outputId":"064bcb18-f3fa-4bd4-d1c5-fdc544abd752"},"source":["nhat.evaluateTest(test_dataset)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9213199, 0.9329485, 0.88321286, 0.90637904)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"0wBJPJ7WUYJd"},"source":["for i in range(x_test.shape[0]):\n","  y_pred = nhat.model(normalize(x_test[i:i+1],y_test[i:i+1]))\n","  y_predShow = np.argmax(y_pred,axis = -1)\n","  plt.figure(i+1)\n","  plt.subplot(131),plt.imshow(x_test[i,...,0],cmap='gray'),plt.title('image')\n","  plt.subplot(132),plt.imshow(y_predShow[0],cmap ='gray'),plt.title('predict')\n","  plt.subplot(133),plt.imshow(y_test[i,...,0],cmap='gray'),plt.title('groundtruth')"],"execution_count":null,"outputs":[]}]}